{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import create_dataloaders\n",
    "\n",
    "# Create dataloaders for all datasets\n",
    "dataloaders = create_dataloaders(\n",
    "    batch_size=32,\n",
    "    train_split=0.9,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    seed=42,\n",
    "    max_samples=100\n",
    ")\n",
    "\n",
    "# Print some statistics\n",
    "for dataset_name, loaders in dataloaders.items():\n",
    "    # Calculate total samples for train and test\n",
    "    train_samples = len(loaders['train'].dataset)\n",
    "    test_samples = len(loaders['test'].dataset)\n",
    "    total_samples = train_samples + test_samples\n",
    "    \n",
    "    print(f\"\\nDataset: {dataset_name}\")\n",
    "    print(f\"Total samples: {total_samples}\")\n",
    "    print(f\"Training samples: {train_samples}\")\n",
    "    print(f\"Test samples: {test_samples}\")\n",
    "    \n",
    "    # Print example sample\n",
    "    batch = next(iter(loaders['train']))\n",
    "    print(\"\\nExample sample:\")\n",
    "    print(f\"Question: {batch['question'][0]}\")\n",
    "    print(f\"Sycophantic answer: {batch['sycophantic_answer'][0]}\")\n",
    "    print(f\"Non-sycophantic answer: {batch['non_sycophantic_answer'][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'mps') #add cpu if needed\n",
    "# Load the Gemma model\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gemma-2b-it\",\n",
    "    device=device, \n",
    "    dtype=torch.float32 #float16 is faster but less accurate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from activations import collect_and_save_activations, load_activation_dataloaders\n",
    "\n",
    "save_dir = \".data/activations\"\n",
    "hooks=[]\n",
    "for layer in range(15,model.cfg.n_layers):\n",
    "        hooks.extend([\n",
    "            # f'blocks.{layer}.hook_resid_pre',  # Before attention\n",
    "            # f'blocks.{layer}.hook_resid_mid',  # After attention, before MLP\n",
    "            f'blocks.{layer}.hook_resid_post'  # After MLP\n",
    "        ])\n",
    "print(len(hooks))\n",
    "\n",
    "# Collect activations for each dataset\n",
    "\n",
    "collect_and_save_activations(\n",
    "    model=model,\n",
    "    train_dataloader=dataloaders['mixed']['train'],\n",
    "    test_dataloader=dataloaders['mixed']['test'],\n",
    "    hooks=hooks,\n",
    "    save_dir=save_dir,\n",
    "    dataset_name='mixed',\n",
    "    print_outputs=False\n",
    ")\n",
    "collect_and_save_activations(\n",
    "    model=model,\n",
    "    train_dataloader=dataloaders['politics']['train'],\n",
    "    test_dataloader=dataloaders['politics']['test'], \n",
    "    hooks=hooks,\n",
    "    save_dir=save_dir,\n",
    "    dataset_name='politics',\n",
    "    print_outputs=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Probe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from probe import train_probe, evaluate_probe\n",
    "\n",
    "# Load activation dataloaders\n",
    "for hook in hooks:\n",
    "    # train on nlp and philosophy\n",
    "    mixed_activation_loaders = load_activation_dataloaders(\n",
    "        save_dir,\n",
    "        model.cfg.model_name,\n",
    "        \"mixed\", \n",
    "        hook=hook,\n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Train probe\n",
    "    probe, losses = train_probe(\n",
    "        mixed_activation_loaders['train'],\n",
    "        input_dim=2048,  # Model's hidden dimension\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "\n",
    "    # Evaluate probe\n",
    "    # test on nlp and philosophy\n",
    "    mixed_results = evaluate_probe(probe, mixed_activation_loaders['test'], device)\n",
    "    #test on politics\n",
    "    politics_activation_loaders = load_activation_dataloaders(  \n",
    "        save_dir,\n",
    "        model.cfg.model_name,\n",
    "        \"politics\", \n",
    "        hook=hook,\n",
    "        batch_size=32\n",
    "    )\n",
    "    politics_results = evaluate_probe(probe, politics_activation_loaders['test'], device)\n",
    "\n",
    "   \n",
    "    print(f\"\\nTest Results:\")\n",
    "    print(f\"Hook: {hook}\")\n",
    "    print(f\"Accuracy: {mixed_results['accuracy']:.2%}\")\n",
    "    print(f\"Total samples: {mixed_results['total_samples']}\")\n",
    "    print(f\"Pol Accuracy: {politics_results['accuracy']:.2%}\")\n",
    "    print(f\"Pol Total samples: {politics_results['total_samples']}\")\n",
    "    print('-'*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test probe on multiple datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation measuring comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAE comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
